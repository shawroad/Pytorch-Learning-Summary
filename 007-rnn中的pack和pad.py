"""
@file   : 007-rnn中的pack和pad.py
@author : xiaolu
@email  : luxiaonlp@163.com
@time   : 2021-04-19
"""
import torch
from torch import nn

if __name__ == "__main__":
    a = torch.randn(3, 4, 5)   # batch_size, max_len, hidden_size
    print(a)
    '''
    tensor([[[ 3.6547e-01,  2.8428e-01, -1.9035e+00, -1.8299e-03,  6.3123e-01],
         [ 1.1418e+00, -1.0706e+00,  1.5557e+00,  2.7764e-01,  3.0979e-01],
         [ 2.9538e-02,  7.7704e-01, -8.0946e-01, -7.9097e-01,  5.9070e-01],
         [ 1.5778e+00, -8.7790e-01, -9.3723e-01, -1.4564e+00,  8.9582e-01]],

        [[-2.1328e+00,  1.4795e-01,  9.2748e-01,  6.7592e-01,  2.2167e+00],
         [ 6.4116e-01, -2.3874e-03, -7.7271e-01,  3.3828e-01,  2.0327e+00],
         [ 6.9315e-01, -1.1815e+00, -1.7080e+00,  6.4167e-01,  5.7590e-03],
         [-4.7120e-01,  3.0666e-01, -5.5505e-01,  4.8492e-01,  8.2848e-01]],

        [[-5.2732e-01,  9.3908e-01, -1.2399e+00,  7.6041e-01, -2.7496e-01],
         [-5.2875e-01,  1.7692e+00,  8.1203e-01,  1.3238e+00, -1.6537e+00],
         [-1.3843e+00,  1.1344e+00, -1.2171e-01, -8.4138e-01,  1.6310e+00],
         [ 2.8643e-01,  3.2076e-01, -1.3454e-01,  2.0516e+00,  4.3703e-01]]])
    '''
    length = [4, 2, 1]
    embedded = nn.utils.rnn.pack_padded_sequence(a, length, batch_first=True)
    print(embedded)   # 把padding的部分直接拿掉了
    '''
    PackedSequence(data=tensor([[ 3.6547e-01,  2.8428e-01, -1.9035e+00, -1.8299e-03,  6.3123e-01],
        [-2.1328e+00,  1.4795e-01,  9.2748e-01,  6.7592e-01,  2.2167e+00],
        [-5.2732e-01,  9.3908e-01, -1.2399e+00,  7.6041e-01, -2.7496e-01],
        [ 1.1418e+00, -1.0706e+00,  1.5557e+00,  2.7764e-01,  3.0979e-01],
        [ 6.4116e-01, -2.3874e-03, -7.7271e-01,  3.3828e-01,  2.0327e+00],
        [ 2.9538e-02,  7.7704e-01, -8.0946e-01, -7.9097e-01,  5.9070e-01],
        [ 1.5778e+00, -8.7790e-01, -9.3723e-01, -1.4564e+00,  8.9582e-01]]), batch_sizes=tensor([3, 2, 1, 1]), sorted_indices=None, unsorted_indices
    '''

    # 然后将pack后的序列输入到rnn中
    rnn = nn.RNN(input_size=5, hidden_size=3, num_layers=1,
                 batch_first=True, bidirectional=True)

    output, hidden = rnn(embedded)
    print(output)    # 输出的也只是没有padding的那部分输出
    '''
    PackedSequence(data=tensor([[ 0.7895,  0.3178,  0.2825,  0.4904, -0.0509,  0.6041],
        [-0.5853, -0.3669,  0.9842, -0.8821,  0.0301,  0.5559],
        [ 0.3816,  0.1997,  0.5488,  0.2503, -0.0719,  0.0303],
        [ 0.5866, -0.2707,  0.5612, -0.9389, -0.2257, -0.1076],
        [-0.0533,  0.8244,  0.2667,  0.2978, -0.6451,  0.3270],
        [ 0.3347,  0.2484,  0.6875, -0.3184,  0.1502,  0.7040],
        [ 0.9054,  0.1010,  0.2043, -0.2821, -0.2302,  0.2397]],
       grad_fn=<CatBackward>), batch_sizes=tensor([3, 2, 1, 1]), sorted_indices=None, unsorted_indices=None)
    '''

    print(hidden)    # 两个方向的输出  这里是最后一步的输出  不包含padding
    '''
    tensor([[[ 0.9054,  0.1010,  0.2043],
         [-0.0533,  0.8244,  0.2667],
         [ 0.3816,  0.1997,  0.5488]],

        [[ 0.4904, -0.0509,  0.6041],
         [-0.8821,  0.0301,  0.5559],
         [ 0.2503, -0.0719,  0.0303]]], grad_fn=<StackBackward>)
    '''

    # 将其还原成有padding的形式
    output, _ = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)
    print(output)   # output自动将前向与后向拼接了
    '''
    tensor([[[ 0.7895,  0.3178,  0.2825,  0.4904, -0.0509,  0.6041],
         [ 0.5866, -0.2707,  0.5612, -0.9389, -0.2257, -0.1076],
         [ 0.3347,  0.2484,  0.6875, -0.3184,  0.1502,  0.7040],
         [ 0.9054,  0.1010,  0.2043, -0.2821, -0.2302,  0.2397]],

        [[-0.5853, -0.3669,  0.9842, -0.8821,  0.0301,  0.5559],
         [-0.0533,  0.8244,  0.2667,  0.2978, -0.6451,  0.3270],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],

        [[ 0.3816,  0.1997,  0.5488,  0.2503, -0.0719,  0.0303],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],
       grad_fn=<TransposeBackward0>)
    '''
    print(_)
    '''
    tensor([4, 2, 1])
    '''
